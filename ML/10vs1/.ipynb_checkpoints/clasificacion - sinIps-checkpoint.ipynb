{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13a22dab",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c281b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fb8916",
   "metadata": {},
   "source": [
    "# creo el cvs a tratar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "087a2204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#malicious_data = pd.read_csv(\"TraficoMalo.csv\")\n",
    "#non_malicious_data = pd.read_csv(\"TraficoBueno.csv\")\n",
    "#malicious_data = pd.read_csv(\"TraficoMaloCompleto.csv\")\n",
    "#non_malicious_data = pd.read_csv(\"TraficoBuenoCompleto.csv\")\n",
    "\n",
    "\n",
    "malicious_data = pd.read_csv(\"10.csv\")\n",
    "non_malicious_data = pd.read_csv(\"1millon.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a42a9",
   "metadata": {},
   "source": [
    "# Limpieza de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d525433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimina datos\n",
    "#columnas_a_eliminar = ['exaddr','engine_type','engine_id','dst_mask','src_mask', 'dst_mask','src_as','dst_as','#:unix_secs','unix_nsecs','sysuptime','first','last','nexthop']\n",
    "columnas_a_eliminar = ['srcaddr','dstaddr','exaddr','engine_type','engine_id','dst_mask','src_mask', 'dst_mask','src_as','dst_as','#:unix_secs','unix_nsecs','sysuptime','first','last','nexthop']\n",
    "malicious_data = malicious_data.drop(columnas_a_eliminar, axis=1)\n",
    "non_malicious_data = non_malicious_data.drop(columnas_a_eliminar, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f5ced0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 747690 entries, 0 to 747689\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count   Dtype\n",
      "---  ------     --------------   -----\n",
      " 0   dpkts      747690 non-null  int64\n",
      " 1   doctets    747690 non-null  int64\n",
      " 2   input      747690 non-null  int64\n",
      " 3   output     747690 non-null  int64\n",
      " 4   srcport    747690 non-null  int64\n",
      " 5   dstport    747690 non-null  int64\n",
      " 6   prot       747690 non-null  int64\n",
      " 7   tos        747690 non-null  int64\n",
      " 8   tcp_flags  747690 non-null  int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 51.3 MB\n"
     ]
    }
   ],
   "source": [
    "malicious_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10b4d011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 747690 entries, 0 to 747689\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count   Dtype\n",
      "---  ------     --------------   -----\n",
      " 0   dpkts      747690 non-null  int64\n",
      " 1   doctets    747690 non-null  int64\n",
      " 2   input      747690 non-null  int64\n",
      " 3   output     747690 non-null  int64\n",
      " 4   srcport    747690 non-null  int64\n",
      " 5   dstport    747690 non-null  int64\n",
      " 6   prot       747690 non-null  int64\n",
      " 7   tos        747690 non-null  int64\n",
      " 8   tcp_flags  747690 non-null  int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 51.3 MB\n"
     ]
    }
   ],
   "source": [
    "malicious_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61fed15",
   "metadata": {},
   "source": [
    "# Clasificación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1dbea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec032d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Agregar una columna de etiquetas a cada conjunto de datos\n",
    "malicious_data['etiqueta'] = 1\n",
    "non_malicious_data['etiqueta'] = 0\n",
    "# Combinar los conjuntos de datos y mezclarlos aleatoriamente\n",
    "datos = pd.concat([malicious_data, non_malicious_data]).sample(frac=1, random_state=42)\n",
    "\n",
    "X = datos.drop('etiqueta', axis=1)\n",
    "y = datos['etiqueta']\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Inicializa el escalador\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Ajusta el escalador a los datos de entrenamiento y luego transforma los datos de entrenamiento\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Usa el escalador ajustado para transformar los datos de prueba\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ddf70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c97959",
   "metadata": {},
   "source": [
    "# KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7121f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Definir los hiperparámetros y sus posibles valores para la búsqueda\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': [10, 20, 30],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Crear una instancia del modelo KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# Aplicar Grid Search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros y puntuaciones\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Crear un nuevo modelo con los mejores hiperparámetros y ajustar los datos\n",
    "best_model = KNeighborsClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones y evaluar el modelo\n",
    "predictions = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print('Mejores hiperparámetros encontrados:', best_params)\n",
    "print('Precisión del modelo con los mejores hiperparámetros: {:.8f}'.format(accuracy))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb4d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Crear una instancia del modelo KNeighborsClassifier con los mejores hiperparámetros\n",
    "best_model1 = KNeighborsClassifier(**best_params)\n",
    "\n",
    "# Ajustar los datos de entrenamiento con el nuevo modelo\n",
    "best_model1.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones utilizando el modelo ajustado\n",
    "predictions = best_model1.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo con las predicciones obtenidas\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Precisión del modelo con los mejores hiperparámetros: {:.2f}%'.format(accuracy * 100))\n",
    "# Se calcula la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Precisión del modelo: {:.2f}%'.format(accuracy * 100))\n",
    "# Recall\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Recall: {:.2f}%'.format(recall * 100))\n",
    "# Precisión\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Precisión: {:.2f}%'.format(precision * 100))\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('F1 Score: {:.2f}%'.format(f1 * 100))\n",
    "\n",
    "print(\"Matriz de confusión:\")\n",
    "\n",
    "# Se imprime la matriz de confusión\n",
    "# Se imprime la matriz de confusión\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No malicioso\", \"Malicioso\"])\n",
    "\n",
    "# Dibuja la matriz de confusión\n",
    "fig, ax = plt.subplots(figsize=(5, 5))  \n",
    "cmd.plot(ax=ax, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a23fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "\n",
    "# Se entrena el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Se hacen predicciones con los datos de prueba\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Se imprime el reporte de clasificación\n",
    "#print(classification_report(y_test, predictions))\n",
    "\n",
    "# Se calcula la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Precisión del modelo: {:.2f}%'.format(accuracy * 100))\n",
    "# Recall\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Recall: {:.2f}%'.format(recall * 100))\n",
    "# Precisión\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Precisión: {:.2f}%'.format(precision * 100))\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('F1 Score: {:.2f}%'.format(f1 * 100))\n",
    "\n",
    "print(\"Matriz de confusión:\")\n",
    "\n",
    "# Se imprime la matriz de confusión\n",
    "# Se imprime la matriz de confusión\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No malicioso\", \"Malicioso\"])\n",
    "\n",
    "# Dibuja la matriz de confusión\n",
    "fig, ax = plt.subplots(figsize=(5, 5))  \n",
    "cmd.plot(ax=ax, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fce265",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab7a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Definir los hiperparámetros y sus posibles valores para la búsqueda\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [1000,2000, 3000]\n",
    "}\n",
    "\n",
    "\n",
    "# Crear una instancia del modelo LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Aplicar Grid Search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros y puntuaciones\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Crear un nuevo modelo con los mejores hiperparámetros y ajustar los datos\n",
    "best_model = LogisticRegression(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones y evaluar el modelo\n",
    "predictions = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print('Mejores hiperparámetros encontrados:', best_params)\n",
    "print('Precisión del modelo con los mejores hiperparámetros: {:.8f}'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b91b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear una instancia del modelo LogisticRegression con los mejores hiperparámetros\n",
    "best_model2 = LogisticRegression(**best_params)\n",
    "\n",
    "# Ajustar los datos de entrenamiento con el nuevo modelo\n",
    "best_model2.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones utilizando el modelo ajustado\n",
    "predictions = best_model2.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo con las predicciones obtenidas\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Precisión del modelo: {:.2f}%'.format(accuracy * 100))\n",
    "\n",
    "# Calcular otras métricas de evaluación\n",
    "recall = recall_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "\n",
    "print('Recall: {:.2f}%'.format(recall * 100))\n",
    "print('Precisión: {:.2f}%'.format(precision * 100))\n",
    "print('F1 Score: {:.2f}%'.format(f1 * 100))\n",
    "\n",
    "print(\"Matriz de confusión:\")\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No malicioso\", \"Malicioso\"])\n",
    "\n",
    "# Dibuja la matriz de confusión\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "cmd.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fde1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "# Se entrena el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Se hacen predicciones con los datos de prueba\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Se imprime el reporte de clasificación\n",
    "#print(classification_report(y_test, predictions))\n",
    "\n",
    "# Se calcula la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Precisión del modelo: {:.2f}%'.format(accuracy * 100))\n",
    "# Recall\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Recall: {:.2f}%'.format(recall * 100))\n",
    "# Precisión\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Precisión: {:.2f}%'.format(precision * 100))\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('F1 Score: {:.2f}%'.format(f1 * 100))\n",
    "\n",
    "print(\"Matriz de confusión:\")\n",
    "\n",
    "# Se imprime la matriz de confusión\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No malicioso\", \"Malicioso\"])\n",
    "\n",
    "# Dibuja la matriz de confusión\n",
    "fig, ax = plt.subplots(figsize=(5, 5))  \n",
    "cmd.plot(ax=ax, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26637b3",
   "metadata": {},
   "source": [
    "# LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184479e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Definir los hiperparámetros y sus posibles valores para la búsqueda\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'max_iter': [1000, 2000, 3000]\n",
    "}\n",
    "\n",
    "# Crear una instancia del modelo LinearSVC\n",
    "model = LinearSVC()\n",
    "\n",
    "# Aplicar Grid Search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros y puntuaciones\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Crear un nuevo modelo con los mejores hiperparámetros y ajustar los datos\n",
    "best_model = LinearSVC(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones y evaluar el modelo\n",
    "predictions = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print('Mejores hiperparámetros encontrados:', best_params)\n",
    "print('Precisión del modelo con los mejores hiperparámetros: {:.8f}'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb411dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear una instancia del modelo LinearSVC con los mejores hiperparámetros\n",
    "best_model3 = LinearSVC(**best_params)\n",
    "\n",
    "# Ajustar los datos de entrenamiento con el nuevo modelo\n",
    "best_model3.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones utilizando el modelo ajustado\n",
    "predictions = best_model3.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo con las predicciones obtenidas\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Precisión del modelo: {:.2f}%'.format(accuracy * 100))\n",
    "\n",
    "# Calcular otras métricas de evaluación\n",
    "recall = recall_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "\n",
    "print('Recall: {:.2f}%'.format(recall * 100))\n",
    "print('Precisión: {:.2f}%'.format(precision * 100))\n",
    "print('F1 Score: {:.2f}%'.format(f1 * 100))\n",
    "\n",
    "print(\"Matriz de confusión:\")\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No malicioso\", \"Malicioso\"])\n",
    "\n",
    "# Dibuja la matriz de confusión\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "cmd.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LinearSVC(max_iter=1000)\n",
    "# Se entrena el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Se hacen predicciones con los datos de prueba\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Se imprime el reporte de clasificación\n",
    "#print(classification_report(y_test, predictions))\n",
    "\n",
    "# Se calcula la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Precisión del modelo: {:.2f}%'.format(accuracy * 100))\n",
    "# Recall\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Recall: {:.2f}%'.format(recall * 100))\n",
    "# Precisión\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Precisión: {:.2f}%'.format(precision * 100))\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('F1 Score: {:.2f}%'.format(f1 * 100))\n",
    "\n",
    "print(\"Matriz de confusión:\")\n",
    "\n",
    "# Se imprime la matriz de confusión\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No malicioso\", \"Malicioso\"])\n",
    "\n",
    "# Dibuja la matriz de confusión\n",
    "fig, ax = plt.subplots(figsize=(5, 5))  \n",
    "cmd.plot(ax=ax, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752df59",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aeba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Definir los hiperparámetros y sus posibles valores para la búsqueda\n",
    "param_grid = {\n",
    "    'penalty': [None, 'l1', 'l2', 'elasticnet'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'max_iter': [1000, 2000, 3000],\n",
    "    'eta0': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "# Crear una instancia del modelo Perceptron\n",
    "model = Perceptron()\n",
    "\n",
    "# Aplicar Grid Search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros y puntuaciones\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Crear un nuevo modelo con los mejores hiperparámetros y ajustar los datos\n",
    "best_model = Perceptron(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones y evaluar el modelo\n",
    "predictions = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print('Mejores hiperparámetros encontrados:', best_params)\n",
    "print('Precisión del modelo con los mejores hiperparámetros: {:.8f}'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed74e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una instancia del modelo Perceptron con los mejores hiperparámetros\n",
    "best_model4 = Perceptron(**best_params)\n",
    "\n",
    "# Ajustar los datos de entrenamiento con el nuevo modelo\n",
    "best_model4.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones utilizando el modelo ajustado\n",
    "predictions = best_model4.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo con las predicciones obtenidas\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Precisión del modelo: {:.2f}%'.format(accuracy * 100))\n",
    "\n",
    "# Calcular otras métricas de evaluación\n",
    "recall = recall_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "\n",
    "print('Recall: {:.2f}%'.format(recall * 100))\n",
    "print('Precisión: {:.2f}%'.format(precision * 100))\n",
    "print('F1 Score: {:.2f}%'.format(f1 * 100))\n",
    "\n",
    "print(\"Matriz de confusión:\")\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No malicioso\", \"Malicioso\"])\n",
    "\n",
    "# Dibuja la matriz de confusión\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "cmd.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f38dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = Perceptron()\n",
    "# Se entrena el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Se hacen predicciones con los datos de prueba\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Se imprime el reporte de clasificación\n",
    "#print(classification_report(y_test, predictions))\n",
    "\n",
    "# Se calcula la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Precisión del modelo: {:.2f}%'.format(accuracy * 100))\n",
    "# Recall\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Recall: {:.2f}%'.format(recall * 100))\n",
    "# Precisión\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Precisión: {:.2f}%'.format(precision * 100))\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('F1 Score: {:.2f}%'.format(f1 * 100))\n",
    "\n",
    "print(\"Matriz de confusión:\")\n",
    "\n",
    "# Se imprime la matriz de confusión\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No malicioso\", \"Malicioso\"])\n",
    "\n",
    "# Dibuja la matriz de confusión\n",
    "fig, ax = plt.subplots(figsize=(5, 5))  \n",
    "cmd.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57014b28",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Desactivar las advertencias\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Definir los hiperparámetros y sus posibles valores para la búsqueda\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None, 0.5, 0.8]\n",
    "}\n",
    "\n",
    "# Crear una instancia del modelo RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Aplicar Grid Search con validación cruzada\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='accuracy', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros y puntuaciones\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Crear un nuevo modelo con los mejores hiperparámetros y ajustar los datos\n",
    "best_model = RandomForestClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones y evaluar el modelo\n",
    "predictions = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Realizar validación cruzada en el mejor modelo\n",
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "cv_mean_score = cv_scores.mean()\n",
    "\n",
    "print('Mejores hiperparámetros encontrados:', best_params)\n",
    "print('Precisión del modelo con los mejores hiperparámetros: {:.8f}'.format(accuracy))\n",
    "print('Precisión media de validación cruzada:', cv_mean_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b99118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear una instancia del modelo RandomForestClassifier con los mejores hiperparámetros\n",
    "best_model5 = RandomForestClassifier(**best_params)\n",
    "\n",
    "# Se entrena el modelo con los datos de entrenamiento\n",
    "best_model5.fit(X_train, y_train)\n",
    "\n",
    "# Se hacen predicciones con los datos de prueba\n",
    "predictions = best_model5.predict(X_test)\n",
    "\n",
    "# Se imprime el reporte de clasificación\n",
    "#print(classification_report(y_test, predictions))\n",
    "\n",
    "# Se calcula la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Precisión del modelo: {:.2f}%'.format(accuracy * 100))\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Recall: {:.2f}%'.format(recall * 100))\n",
    "\n",
    "# Precisión\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Precisión: {:.2f}%'.format(precision * 100))\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('F1 Score: {:.2f}%'.format(f1 * 100))\n",
    "\n",
    "print(\"Matriz de confusión:\")\n",
    "# Se imprime la matriz de confusión\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No malicioso\", \"Malicioso\"])\n",
    "\n",
    "# Dibuja la matriz de confusión\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "cmd.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1abdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "# Se entrena el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Se hacen predicciones con los datos de prueba\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Se imprime el reporte de clasificación\n",
    "#print(classification_report(y_test, predictions))\n",
    "\n",
    "# Se calcula la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Precisión del modelo: {:.2f}%'.format(accuracy * 100))\n",
    "# Recall\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Recall: {:.2f}%'.format(recall * 100))\n",
    "# Precisión\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Precisión: {:.2f}%'.format(precision * 100))\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('F1 Score: {:.2f}%'.format(f1 * 100))\n",
    "\n",
    "print(\"Matriz de confusión:\")\n",
    "# Se imprime la matriz de confusión\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No malicioso\", \"Malicioso\"])\n",
    "\n",
    "# Dibuja la matriz de confusión\n",
    "fig, ax = plt.subplots(figsize=(5, 5))  \n",
    "cmd.plot(ax=ax, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eccc6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c5c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "# Crear el ensemble classifier con votación mayoritaria\n",
    "ensemble_model = VotingClassifier(estimators=[('lr', best_model2), ('perceptron', best_model4), ('lsvc', best_model3), ('rf', best_model5), ('knn', best_model1)], voting='hard')\n",
    "\n",
    "# Entrenar el ensemble classifier\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones con el ensemble classifier\n",
    "predictions = ensemble_model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del ensemble classifier\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Precisión del ensemble classifier: {:.2f}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2a7033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86feb7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
